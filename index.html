<html lang="en">
  <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-168911195-1"></script>
    <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-168911195-1');
</script> <title>Zhengxia Zou, Ph.D.</title>
    <title>Bootstrap Example</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.3.1.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <style type="text/css">
		.bgimg {
    background-image: url("zzx_gallery/logo.png");
    background-repeat: no-repeat;
    background-position: center; 
    position: relative;
		}
		</style>
  </head>
  <body>
    <div class="container">
      <div class="container">
        <nav class="nav nav-tabs">
          <li><a href="#me">About</a></li>
          <li><a href="#highlights">Research</a></li>
          <li><a href="#Publications">Publication</a></li>
          <li><a href="#Activities">Misc</a></li>
        </nav>
      </div>
      <div class="container">
        <div class="page-header">
          <h2 id="me">Zhengxia Zou, Ph.D.</h2>
        </div>
      </div>
      <div class="container">
        <div class="row">
          <div class="col-sm-4"> <img class="img-responsive img-rounded" style="width:100%"

              src="zzx_gallery/zzx3.jpg"> </div>
          <div class="col-sm-8">
            <p></p>
            I am currently a Professor at the School of Astronautics, <a href="https://www.buaa.edu.cn/"

              target="_blank">Beihang University</a>. I received my Ph.D. and
            B.S. from Beihang University in 2018 and 2013, supervised by Prof. <a

              href="http://levir.buaa.edu.cn/" target="_blank">Zhenwei Shi</a>.
            During 2018 - 2021, I was a postdoc research fellow at the <a href="https://umich.edu/"

              target="_blank">University of Michigan, Ann Arbor</a>, working
            with <a href="http://www.yelabs.net/" target="_blank">Prof. Jieping
              Ye</a> and <a href="https://traffic.engin.umich.edu/" target="_blank">Prof.
              Henry Liu</a>. I study computer vision and related problems in
            remote sensing, autonomous driving, and video games.
            <p></p>
            Email: zhengxiazou [at] gmail [dot] com; zhengxiazou [at] buaa [dot]
            edu [dot] cn
            <p></p>
            <a href="https://shi.buaa.edu.cn/zouzhengxia" target="_blank">[中文主页]</a>
            | <a href="https://scholar.google.com/citations?user=DzwoyZsAAAAJ&amp;hl=en"

              target="_blank">[Google Scholar Profile]</a> | <a href="https://github.com/jiupinjia"

              target="_blank">[Github Profile]</a><br>
            <p></p>
            <p><span style="color: #cc0000;">[Intern position]: I am hiring
                self-motivated graduate/undergraduate students. </span><span style="color: #cc0000;"><span

                  style="color: #cc0000;">Intern </span>positions are always
                available. Please email me with your CV if you are interested.</span>
            </p>
            <p>NEW (04/2023): Our paper on driving environment simulation got
              accepted to Nature Communications.</p>
            <p>NEW (03/2023): Our paper on autonomous vehicle testing got
              accepted to Nature (cover)! Congratulations!</p>
            <p>NEW (02/2023): One paper accepted to CVPR 2023 (featured in New
              Scientist (新科学人)).</p>
            <p>NEW (01/2023): Our survey paper on object detection got accepted
              by Proceedings of the IEEE<em>.</em></p>
            <p> NEW (10/2022): I was listed in the top 2% scientists worldwide
              identified by Stanford University<em>.</em></p>
            <p>NEW (07/2022): One paper accepted to IEEE Transactions on Image
              Processing (TIP)<em>.</em></p>
            <p>NEW (02/2022): One paper accepted to ICRA 2022<em>.</em></p>
            <p>NEW (12/2021): One paper accepted to AAAI 2022, oral presentation<em>.</em></p>
            <p>NEW (06/2021): <a href="https://jiupinjia.github.io/neuralpainter/"

                target="_blank">Stylized Neural Painting</a> launched as a new
              feature in two AI photo editors: <span style="color: #23527c;"><span

                  style="color: #333333;">REMINI</span></span><span style="color: #23527c;"><span

                  style="color: #333333;"> ( </span></span><a href="https://play.google.com/store/apps/details?id=com.bigwinepot.nwdn.international&amp;hl=en_US&amp;gl=US"

                target="_blank">Google Play</a> | <a href="https://apps.apple.com/us/app/remini-ai-photo-enhancer/id1470373330"

                target="_blank">IOS App Store</a> ) <span style="color: #23527c;"><span

                  style="color: #333333;">and 你我当年 </span></span>( <a href="https://app.mi.com/details?id=com.bigwinepot.nwdn"

                target="_blank">XIAOMI App Sstore</a> | <a href="https://apps.apple.com/cn/app/%E4%BD%A0%E6%88%91%E5%BD%93%E5%B9%B4-%E7%85%A7%E7%89%87%E8%A7%86%E9%A2%91%E5%8F%98%E9%AB%98%E6%B8%85-%E8%80%81%E7%85%A7%E7%89%87%E4%BF%AE%E5%A4%8D%E8%A7%86%E9%A2%91%E7%94%BB%E8%B4%A8%E4%BC%98%E5%8C%96%E5%A2%9E%E5%BC%BA/id1461690800"

                target="_blank">IOS App Store </a>), with over 10M users
              worldwide.</p>
            <p>NEW (02/2021): One paper accepted to CVPR 2021, oral
              presentation.</p>
            <p> </p>
          </div>
        </div>
      </div>
      <div class="container">
        <div class="page-header">
          <h2 id="highlights">Research Highlights</h2>
        </div>
      </div>
      <div class="container">
        <div class="panel panel-default">
          <div class="panel-heading"><b>Research impact, media coverage, and
              featured applications</b><br>
          </div>
          <div class="panel-body">
            <div class="row">
              <div class="col-sm-6">
                <ul>
                  <li><i>50+ peer-reviewed publications, including 30+ top-tier
                      journals and conferences ( Nature, Nat. Commun., Proc
                      IEEE, TPAMI, TIP, CVPR, ICCV, AAAI, ... )&nbsp; </i></li>
                  <li><i><i>3000+ Google Scholar citations, </i>4000+ GitHub
                      Stars/Forks </i></li>
                  <li><i> Two papers selected in PaperWithCode "Top-10 Trending
                      Research" and "GitHub Trending Repositories"<b><br>
                      </b></i></li>
                </ul>
              </div>
              <div class="col-sm-6">
                <ul>
                  <li><i>Featured in 10+ platforms with over 10M registered
                      users worldwide, including </i><i><i><i><a href="https://mcity.umich.edu/"

                            target="_blank">MCITY</a>,</i> </i></i><i> <a href="https://apps.apple.com/us/app/remini-ai-photo-enhancer/id1470373330"

                        target="_blank"> REMINI</a>, <a href="https://apps.apple.com/cn/app/%E4%BD%A0%E6%88%91%E5%BD%93%E5%B9%B4/id1461690800?l=en"

                        target="_blank">你我当年</a>, </i><i><a href="https://n.163.com/"

                        target="_blank">Justice</a>, <a href="https://apps.apple.com/cn/app/%E4%BD%A0%E6%88%91%E5%BD%93%E5%B9%B4-%E7%85%A7%E7%89%87%E8%A7%86%E9%A2%91%E5%8F%98%E9%AB%98%E6%B8%85-%E8%80%81%E7%85%A7%E7%89%87%E4%BF%AE%E5%A4%8D%E8%A7%86%E9%A2%91%E7%94%BB%E8%B4%A8%E4%BC%98%E5%8C%96%E5%A2%9E%E5%BC%BA/id1461690800"

                        target="_blank">Heaven Mobile</a>, <a href="https://wandb.ai/site"

                        target="_blank">Weights&amp;Biases</a>, <a href="https://replicate.ai/"

                        target="_blank">REPLICATE AI</a>, <a href="https://runwayml.com/"

                        target="_blank"> RUNWAYML</a></i><i>...<br>
                    </i></li>
                  <li><i>Covered by 30+ high-impact tech-media, including</i><i><i>
                      </i></i><i><i><i><i><a href="http://www.news.cn/politics/2022-03/02/c_1128428941.htm"

                              target="_blank">新华社</a>,</i></i> <a href="http://tv.cctv.com/2022/01/19/VIDEJ78zT7md9otWzW5qgT6N220119.shtml"

                          target="_blank">中央电视台</a>,</i><a href="https://thenextweb.com/neural/2020/11/16/this-open-source-ai-tool-can-make-your-video-spectacular-with-sky-replacement-effects/"

                        target="_blank"> TheNextWeb</a>, <a href="https://www.newscientist.com/article/2362730-character-creator-ai-puts-barack-obama-or-anyone-in-a-video-game/"

                        target="_blank">New Scientist</a>, <a href="https://www.jiqizhixin.com/articles/2020-10-25"

                        target="_blank">机器之心</a>, <a href="https://mp.weixin.qq.com/s/xowoCSI6yIrzPTavz4OiLg"

                        target="_blank">量子位</a>...</i> </li>
                </ul>
              </div>
            </div>
          </div>
        </div>
        <div class="container">
          <div class="page-header">
            <h2 id="Publications">Selected Publications</h2>
          </div>
        </div>
        <div class="container">
          <div class="panel panel-default">
            <div class="panel-heading"><b>Selected publications and preprints
                (*For my full publication list, please go to my <a href="https://scholar.google.com/citations?user=DzwoyZsAAAAJ&amp;amp;hl=en"

                  target="_blank">google scholar profile</a>)</b> </div>
            <div class="panel-body">
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-DetectionSurvey.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p> <b>Zhengxia Zou*</b> (*Corresponding author), Zhenwei
                    Shi, Yuhong Guo, and Jieping Ye (*Corresponding author).
                    Object Detection in 20 Years: A Survey. <i>Proceedings of
                      the IEEE</i>, Volumn 111, Issue 13, 2023. [1500+ citations], <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5"
                      target="_blank">Most Popular Article of the PIEEE 2023</a>. <a href="https://ieeexplore.ieee.org/document/10028728"
                      target="_blank">[PDF]</a></p>
                   Extensively reviews the fast-moving research field of object detection in the light of technical evolution,
                  spanning over a quarter-century's time (from the 1990s to 2022). A number of
                  topics are covered in this paper, including milestone
                  detectors, detection datasets, metrics, fundamental building
                  blocks of detection systems, speed up techniques, and the
                  recent state of the art detection methods.
                  <p></p>
                  <b>- High-impact citations:&nbsp;</b> <a href="http://cs231n.stanford.edu/"

                    target="_blank"><u>Stanford CS231n: Convolutional Neural
                      Networks for Visual Recognition (2019-2023).</u></a>
                  <p></p>
                  <p></p>
                  <b>- Media coverage:</b> <a href="https://proceedingsoftheieee.ieee.org/category/media-room/blog/"

                    target="_blank"><u>[PIEEE] Proceedings of the IEEE Paper Explores Object Detection's Evolution and Future Directions</u></a>&nbsp;|

                  <a href="https://www.zhuanzhi.ai/document/50b8a2fec4a9ad5561b8694d16a1dffb"

                    target="_blank"><u>[专知] 密歇根大学40页最新论文带你全面了解目标检测</u></a>&nbsp;
                  <p></p>
                  <b>- In other languages:</b>&nbsp; <a href="https://ai.yanxishe.com/page/postDetail/14275"

                    target="_blank"><u>English-to-Chinese (1)</u></a> |&nbsp; <a

                    href="https://blog.csdn.net/clover_my/article/details/92794719"

                    target="_blank"><u>English-to-Chinese (2)</u></a>&nbsp;
                  <p></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-NeuralNDE.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p> Xintao Yan+, <b><strong></strong>Zhengxia Zou</b>+
                    (+equal contribution), Shuo Feng, Haojie Zhu, Haowei Sun,
                    Henry X. Liu* (*Corresponding author)<strong></strong>.
                    Learning Naturalistic Driving Environment with Statistical
                    Realism. <i><i>Nature Communications (featured image), 2023</i>. </i>Featured
                    in <a target="_blank" href="https://www.nature.com/collections/hjhbgijcei">Editors'
                      Highlights</a>.<i> </i><a href="https://www.nature.com/articles/s41467-023-37677-5"

                      target="_blank">[PDF]</a><em> </em><a href="https://github.com/michigan-traffic-lab/Learning-Naturalistic-Driving-Environment"

                      target="_blank">[Github]</a>&nbsp;<i> </i></p>
                  <p>We develop NeuralNDE, a Transformer-based framework to
                    learn multi-agent interaction behavior from real-world
                    vehicle trajectory data. NeuralNDE can achieve both accurate
                    safety-critical and normal driving statistics.</p>
                  <p> </p>
                  <p></p>
                  <b>- Media coverage:&nbsp; </b><a href="https://www.eurekalert.org/news-releases/987857"

                    target="_blank"><u>[EurekAlert]</u></a> <a href="https://techxplore.com/news/2023-05-world-realistic-simulated-environment-based.html"

                    target="_blank"><u>[TechXplore]</u></a> <a href="https://news.umich.edu/worlds-first-realistic-simulated-driving-environment-based-on-crash-prone-michigan-intersection/"

                    target="_blank"><u>[Michigan News] World’s first realistic
                      simulated driving environment based on ‘crash-prone’
                      Michigan intersection.</u></a> | <a href="https://www.sohu.com/a/674403685_610300"

                    target="_blank"><u>[量子位]
                      自动驾驶仿真系统登Nature子刊，准确建模事故率事故类型，全华人团队打造</u></a> | <a href="https://www.mittrchina.com/news/detail/11938"

                    target="_blank"><u>[MIT科技评论]
                      密西根大学团队开发高精度自然驾驶仿真算法，为自动驾驶开发提供仿真基础</u></a>
                  <p></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/nature.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p> Shuo Feng, Haowei Sun, Xintao Yan, Haojie Zhu, <b>Zhengxia
                      Zou</b>, Shengyin Shen, Henry X. Liu* (*Corresponding
                    author). Dense Reinforcement Learning for Safety Validation
                    of Autonomous Vehicles. <i>Nature (cover)</i>, 2023<i>.</i>
                    <em> </em><a href="https://www.nature.com/articles/s41586-023-05732-2"

                      target="_blank">[PDF]</a><em> </em><a href="https://github.com/michigan-traffic-lab/Dense-Deep-Reinforcement-Learning"

                      target="_blank">[Github]</a>&nbsp;<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9197693"

                      target="_blank"></a><i> </i></p>
                  <p>One critical bottleneck that impedes the development and
                    deployment of autonomous vehicles is the prohibitively high
                    economic and time costs required to validate their safety in
                    a naturalistic driving environment, owing to the rarity of
                    safety-critical events. Here we report the development of an
                    intelligent testing environment, where
                    artificial-intelligence-based background agents are trained
                    to validate the safety performances of autonomous vehicles
                    in an accelerated mode, without loss of unbiasedness.</p>
                  <p> </p>
                  <p> </p>
                  <b>- Media coverage:</b> <a href="https://www.nature.com/articles/d41586-023-00798-4"

                    target="_blank"><u>[Nature News] Hazards help autonomous
                      cars to drive safely.</u></a> | <a href="https://www.nature.com/articles/d41586-023-00867-8"

                    target="_blank"><u>[Nature Podcast] How to make driverless
                      cars safer — expose them to lots of dangerous drivers</u></a>
                  | <a href="https://news.engin.umich.edu/2023/03/simulated-terrible-drivers-cut-the-time-and-cost-of-av-testing-by-a-factor-of-one-thousand/"

                    target="_blank"><u>[Michigan Engineering] Simulated terrible
                      drivers cut the time and cost of AV testing by a factor of
                      one thousand</u></a>
                  <p></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-T2P.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p> Rui Zhao, Wei Li, Zhipeng Hu, Lincheng Li* (*Corresponding
                    author), <b>Zhengxia Zou*</b> (*Corresponding author),
                    Zhenwei Shi, Changjie Fan<strong></strong>. Zero-Shot
                    Text-to-Parameter Translation for Game Character
                    Auto-Creation. Accepted to <em><em>IEEE Conference on
                        Computer Vision and Pattern Recognition (CVPR) 2023</em></em><i>.</i><i>
                    </i><a href="https://arxiv.org/abs/2303.01311" target="_blank">[PDF]</a>
                  </p>
                  <p> </p>
                  <b>- Featured apps:</b> Justice Mobile (The first plausible
                  solution for text-driven game characters auto-creation).
                  <p></p>
                  <p> </p>
                  <b>- Media coverage:</b> <a href="https://www.newscientist.com/article/2362730-character-creator-ai-puts-barack-obama-or-anyone-in-a-video-game/"

                    target="_blank"><u>[New Scientist (新科学人)] Character creator
                      AI puts Barack Obama – or anyone – in a video game</u></a>
                  <br>
                  <p></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-FaceParams-pami.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p> Tianyang Shi+, <b><strong></strong>Zhengxia Zou</b>+
                    (+equal contribution), Zhenwei Shi, and Yi Yuan*
                    (*Corresponding author)<strong></strong>. Neural Rendering
                    for Game Character Auto-creation. <i><i>IEEE Transactions
                        on Pattern Analysis and Machine Intelligence, 2022</i>.
                    </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9197693"

                      target="_blank">[PDF]</a> <br>
                  </p>
                  <p> </p>
                  <b>- Featured apps:</b> <a href="https://n.163.com/" target="_blank">Justice</a>
                  and <a href="https://apps.apple.com/cn/app/%E4%BD%A0%E6%88%91%E5%BD%93%E5%B9%B4-%E7%85%A7%E7%89%87%E8%A7%86%E9%A2%91%E5%8F%98%E9%AB%98%E6%B8%85-%E8%80%81%E7%85%A7%E7%89%87%E4%BF%AE%E5%A4%8D%E8%A7%86%E9%A2%91%E7%94%BB%E8%B4%A8%E4%BC%98%E5%8C%96%E5%A2%9E%E5%BC%BA/id1461690800"

                    target="_blank">Heaven Mobile</a>, two MMO-RPGs with 10M+
                  players worldwide
                  <p></p>
                  <p> </p>
                  <b>- Media coverage:</b> <a href="http://tv.cctv.com/2022/01/19/VIDEJ78zT7md9otWzW5qgT6N220119.shtml"

                    target="_blank"><u>[CCTV经济信息联播]元宇宙应用渐热 记者走入“元宇宙”
                      体验个性化“捏脸”和动作捕捉</u></a> | <a href="https://www.jiqizhixin.com/articles/2019-09-09-18"

                    target="_blank"><u>[机器之心] 只需一张自拍，网易伏羲用这种方法直接生成「个人专属」游戏角色</u></a><br>
                  <p></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-SkyAR.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p> <b>Zhengxia Zou </b>(*Corresponding author), Rui Zhao,
                    Tianyang Shi, Shuang Qiu, and Zhenwei Shi. Castle in the
                    Sky: Dynamic Sky Replacement and Harmonization in Videos. <em>IEEE
                      Transactions on Image Processing,</em> 2022. In press. <a

                      href="https://arxiv.org/abs/2010.11800" target="_blank">[PDF]</a><em>
                    </em><a href="https://jiupinjia.github.io/skyar/" target="_blank">[Project]</a>
                    [<a target="_blank" href="https://github.com/jiupinjia/SkyAR">GitHub
                      (2.0k☆)</a>]</p>
                  <p><b><b><b>- Featured </b>apps:</b></b><span style="color: #337ab7;"></span>
                    <a href="https://wandb.ai/wandb/skyAR/reports/The-Sky-Is-In-Our-Grasp---VmlldzozMjY0NDI"

                      target="_blank"><u>Weights &amp; Biases</u></a>, a ML
                    developer tool with 100,000+ practitioners </p>
                  <p> </p>
                  <b>- Media coverage:</b> <a href="https://www.jiqizhixin.com/articles/2020-10-25"

                    target="_blank"><u>[机器之心]
                      建造自己的“天空之城”，密歇根大学博士后的这项研究可以虚空造物、偷天换日</u></a> | <a href="https://thenextweb.com/neural/2020/11/16/this-open-source-ai-tool-can-make-your-video-spectacular-with-sky-replacement-effects/"

                    target="_blank"><u>[TNW] This open-source AI tool can make
                      your video spectacular with...</u></a>
                  <p></p>
                  <span style="color: #337ab7;"></span> <span style="color: #337ab7;">
                  </span>
                  <p></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-roadside.jpg"><br>
                  <br>
                </div>
                <div class="col-sm-9">
                  <p></p>
                  <p> <b>Zhengxia Zou</b>, Rusheng Zhang, Shengyin Shen, Gaurav
                    Pandey, Punarjay Chakravarty, Armin Parchami, and Henry X.
                    Liu (*Corresponding author). Real-time Full-stack Traffic
                    Scene Perception for Autonomous Driving with Roadside
                    Cameras. <em><i>The International Conference on Robotics
                        and Automation (ICRA), 2022</i></em><em><i><em></em></i><em></em><em></em>.</em><a

                      href="https://www.youtube.com/watch?v=RkiKe5UNzXA" target="_blank">
                      <em> </em></a><a href="https://arxiv.org/abs/2206.09770"

                      target="_blank">[PDF]</a> <a href="https://www.youtube.com/watch?v=RkiKe5UNzXA"

                      target="_blank">[1min-DemoVideo] </a> </p>
                  <p> <b>- Featured apps:</b> Deployed at a two-lane roundabout
                    located at Ellsworth Rd. and State St., Ann Arbor, MI, USA,
                    providing 7x24 real-time traffic flow monitoring for
                    hazardous driving scenarios identification.</p>
                </div>
              </div>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-ImMPI.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p> Yongchang Wu, <b>Zhengxia Zou</b>* (*Corresponding
                    author), and Zhenwei Shi. Remote Sensing Novel View
                    Synthesis with Implicit Multiplane Representations. <i><em>IEEE
                        Transactions on Geoscience and Remote Sensing, 2022</em></i><em></em><em><i><em></em></i><em></em><em></em>.</em>
                    <em> </em><a href="https://arxiv.org/abs/2205.08908" target="_blank">[PDF]</a><em>
                    </em><a href="https://github.com/wyc-Chang/ImMPI" target="_blank">[Github]</a>
                  </p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-Finegrained.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p>Jianqi Chen, Keyan Chen, Hao Chen, Wenyuan Li, <b>Zhengxia
                      Zou</b>* (*Corresponding author), and Zhenwei Shi.
                    Contrastive Learning for Fine-grained Ship Classification in
                    Remote Sensing Images.&nbsp; <i><em>IEEE Transactions on
                        Geoscience and Remote Sensing, 2022</em></i>. <em> </em><a

                      href="https://ieeexplore.ieee.org/document/9832938/" target="_blank">[PDF]</a><em></em>
                  </p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-PDASS.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p> Liqin Liu, Wenyuan Li, Zhenwei Shi, and <b>Zhengxia Zou</b>*
                    (*Corresponding author). Physics-informed Hyperspectral
                    Remote Sensing Image Synthesis with Deep Conditional
                    Generative Adversarial Networks.&nbsp; <i><em>IEEE
                        Transactions on Geoscience and Remote Sensing, 2022</em></i>.
                    <em> </em><a href="https://ieeexplore.ieee.org/document/9770778/"

                      target="_blank">[PDF]</a><em> </em><a href="https://github.com/liuliqin/PDASS-Physics-informed-HSI-Synthesis-with-Deep-CGAN"

                      target="_blank">[Github]</a> </p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-SSMCT.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p> Yinglin Duan, Yue Lin, <b>Zhengxia Zou</b>*
                    (*Corresponding author), Yi Yuan, Zhehui Qian, Bohan Zhang.
                    A Unified Framework for Real Time Motion Completion.&nbsp;<em><i>AAAI
                        Conference on Artificial Intelligence (AAAI) 2022</i></em><em><em>,
                        <span style="color: #cc0000;">Oral Presentation</span></em></em><em><i><em></em></i><em></em><em></em>.
                    </em><a target="_blank" href="https://ojs.aaai.org/index.php/AAAI/article/view/20368">[PDF]</a><em><br>
                    </em></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-painting.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p> <b>Zhengxia Zou </b>(*Corresponding author), Tianyang
                    Shi, Shuang Qiu, Yi Yuan, and Zhenwei Shi. Stylized Neural
                    Painting.&nbsp;<em><em>IEEE Conference on Computer Vision
                        and Pattern Recognition (CVPR) 2021, <span style="color: #cc0000;">Oral
                          Presentation</span>.</em></em><em> </em><a href="https://arxiv.org/abs/2011.08114"

                      target="_blank">[PDF]</a><em> </em><a href="https://jiupinjia.github.io/neuralpainter/"

                      target="_blank">[Project] </a><a href="https://github.com/jiupinjia/stylized-neural-painting"

                      target="_blank">[GitHub (1.5k☆)]</a></p>
                  <p> <b><b>- Featured </b>apps:</b> <a href="https://play.google.com/store/apps/details?id=com.bigwinepot.nwdn.international&amp;hl=en_US&amp;gl=US"

                      target="_blank">REMINI</a> and <a href="https://apps.apple.com/cn/app/%E4%BD%A0%E6%88%91%E5%BD%93%E5%B9%B4-%E7%85%A7%E7%89%87%E8%A7%86%E9%A2%91%E5%8F%98%E9%AB%98%E6%B8%85-%E8%80%81%E7%85%A7%E7%89%87%E4%BF%AE%E5%A4%8D%E8%A7%86%E9%A2%91%E7%94%BB%E8%B4%A8%E4%BC%98%E5%8C%96%E5%A2%9E%E5%BC%BA/id1461690800"

                      target="_blank">你我当年</a>, two photo editors with 10M+
                    users worldwide | <b> </b><span style="color: #337ab7;"></span>
                    <a href="https://runwayml.com/" target="_blank">RunwayML</a>,
                    a web-based video editor</p>
                  <p> </p>
                  <b>- Media coverage:</b>&nbsp; <a href="http://www.news.cn/politics/2022-03/02/c_1128428941.htm"

                    target="_blank"><u>[新华社] 动动手，一起为春天中国“添彩” - 送您一支AI画笔,
                      为祖国春天涂抹万千风情</u></a> |&nbsp; <a href="https://www.jiqizhixin.com/articles/2021-04-21-5"

                    target="_blank"><u>[机器之心] 有了这支矢量神经风格画笔，无需GAN也可生成精美绘画</u></a>
                  | <a href="https://www.marktechpost.com/2020/11/22/stylized-neural-painter-an-image-to-painting-translation-method-that-generates-vivid-and-realistic-painting-artworks-with-controllable-styles/"

                    target="_blank"><u>[MarkTechPost] An Image-To-Painting
                      Translation Method That Generates Painting Artworks With
                      Controllable Styles</u></a>
                  <p></p>
                  <span style="color: #337ab7;"> </span>
                  <p></p>
                  <p></p>
                  <b></b>
                  <p></p>
                  <p></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-DAD.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p> <b>Zhengxia Zou</b> (*Corresponding author), Sen Lei,
                    Tianyang Shi, Zhenwei Shi, and Jieping Ye. Deep Adversarial
                    Decomposition: A Unified Framework for Separating
                    Superimposed Images. <em>IEEE Conference on Computer Vision
                      and Pattern Recognition (CVPR) 2020. </em><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Zou_Deep_Adversarial_Decomposition_A_Unified_Framework_for_Separating_Superimposed_Images_CVPR_2020_paper.pdf"

                      target="_blank">[PDF]</a><em></em> <a href="https://github.com/jiupinjia/Deep-adversarial-decomposition"

                      target="_blank">[Github]</a></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-inverseGANs.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p> <b>Zhengxia Zou</b> (*Corresponding author), Tianyang
                    Shi, Zhenwei Shi, and Jieping Ye. Adversarial Training for
                    Solving Inverse Problems in Image Processing. <i><em>IEEE
                        Transactions on Image Processing, </em></i><em>2021. </em><a

                      href="https://ieeexplore.ieee.org/document/9337199" target="_blank">[PDF]</a><em>
                    </em><a href="https://www.youtube.com/watch?v=3ZNinJUlXNc" target="_blank">[1min-DemoVideo]</a>
                    <a href="https://github.com/jiupinjia/GANs-for-Inverse-Problems"

                      target="_blank">[Github]</a></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-cloudgan.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p> <b>Zhengxia Zou</b> (*Corresponding author), Wenyuan Li,
                    Tianyang Shi, Zhenwei Shi, and Jieping Ye. Generative
                    Adversarial Training for Weakly Supervised Cloud Matting. <i>IEEE
                      International Conference on Computer Vision (ICCV) 2019.</i>
                    <a href="http://openaccess.thecvf.com/content_ICCV_2019/html/Zou_Generative_Adversarial_Training_for_Weakly_Supervised_Cloud_Matting_ICCV_2019_paper.html"

                      target="_blank">[PDF]</a> <a href="https://github.com/jiupinjia/CloudMattingGAN"

                      target="_blank">[Github]</a></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-RAM.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p><strong>Zhengxia Zou</strong>, and Zhenwei Shi
                    (*Corresponding author). Random access memories: A new
                    paradigm for target detection in high resolution aerial
                    remote sensing images.&nbsp;<i><i><i><em>IEEE Transactions
                            on Image Processing,</em></i> 2018</i>.</i></p>
                  <p> </p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-SVDNet.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p><b>Zhengxia Zou</b>, and Zhenwei Shi (*Corresponding
                    author). Ship Detection in Spaceborne Optical Image With SVD
                    Networks.&nbsp;<i><i><i><em>IEEE Transactions on Geoscience
                            and Remote Sensing,</em></i> 2016</i>.</i></p>
                  <p> </p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-RSCaption.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p>Zhenwei Shi, and <b>Zhengxia Zou</b>* (Corresponding
                    author). Can a machine generate humanlike language
                    descriptions for a remote sensing image? <i><i><i><em>IEEE
                            Transactions on Geoscience and Remote Sensing,</em></i>
                        2017</i>.</i></p>
                  <p> </p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-HCEM.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p><b>Zhengxia Zou</b>, and Zhenwei Shi (*Corresponding
                    author). Hierarchical suppression method for hyperspectral
                    target detection. <i>IEEE Transactions on Geoscience and
                      Remote Sensing, 2015.</i></p>
                  <p> </p>
                </div>
              </div>
              <br>
            </div>
          </div>
          <div class="container">
            <div class="page-header">
              <h2 id="Activities">Teaching and Academic Activities</h2>
            </div>
          </div>
          <div class="container">
            <div class="panel panel-default">
              <div class="panel-heading"><b>Teaching</b> </div>
              <div class="panel-body">
                <ul>
                  <li>Fundamentals of Mathematics for Machine Learning, undergraduate course, 2023/2024 Spring, 48/48 Hours.</li>
                  <li>Pattern Recognition, undergraduate course, 2023/2024 Spring, 16/ 48 Hours.</li>
                  <li>Principles of Intelligent Detection and Control in Aerospace, undergraduate course, 2022/2023 Fall, 16/48 Hours.</li>
                  <li>Intelligent Perception Micro-Class, 2024 Spring, 16/16 Hours.</li>
                  <li>Theoretical and Frontier Research in Intelligent Information Processing, Ph.D. Course, 2024 Fall, 10/32 Hours.</li>
                  <li>Deep Learning for Remote Sensing Image Processing, International Students (English), 2023 Fall, 16/16 Hours.</li>
                </ul>
              </div>
            </div>
          </div>
          <div class="container">
            <div class="panel panel-default">
              <div class="panel-heading"><b>Academic Services</b> </div>
              <div class="panel-body">
                <ul>
                  <li>Secretary-General, Publicity Working Committee, China Society of Image and Graphics (2022-Present).</li>
                  <li>Committee Member, Remote Sensing Image Professional Committee, China Society of Image and Graphics (2023-Present).</li>
                  <li>Academic Advisor, NetEase Fuxi AI Lab (2019-2021).</li>
                </ul>
              </div>
            </div>
          </div>
          <div class="container">
            <div class="panel panel-default">
              <div class="panel-heading"><b>Guest Editor</b> </div>
              <div class="panel-body">
                <ul>
                  <li>Remote Sensing (IF=5.349) Special Issue: "<a href="https://www.mdpi.com/journal/remotesensing/special_issues/6AOG7RGXG8"
                      target="_blank">Pattern Recognition and Image Processing
                      for Remote Sensing III</a>". Deadline: 5 January 2024.</li>
                  <li>Remote Sensing (IF=5.349) Special Issue: "<a href="https://www.mdpi.com/journal/remotesensing/special_issues/pattern_recognition_image_processing_II"
                      target="_blank">Pattern Recognition and Image Processing
                      for Remote Sensing II</a>". Deadline: closed (30 June 2023).</li>
                  <li>Remote Sensing (IF=5.349) Special Issue: "<a href="https://www.mdpi.com/journal/remotesensing/special_issues/RS_Image_Quality_Improvement"
                      target="_blank">Advanced Learning Techniques for Remote
                      Sensing Image Quality Improvement</a>". Deadline: 31 August 2023.</li>
                  <li>Remote Sensing (IF=5.349) Special Issue: "<a href="https://www.mdpi.com/journal/remotesensing/special_issues/CIALT_RS"
                      target="_blank">Computational Intelligence and Advanced
                      Learning Techniques in Remote Sensing</a>". Deadline: closed (31 July 2021).</li>
                </ul>
              </div>
            </div>
          </div>
          <div class="container">
            <div class="panel panel-default">
              <div class="panel-heading"><b>Peer-Review Services</b> </div>
              <div class="panel-body">
                <ul>
                  <li>Senior Program Committee (SPC) member of IJCAI 2021.</li>
                  <li>CVPR 2020, 2021, 2022 PC Member; NeurIPS 2019, 2020 PC
                    Member; ICCV 2021 Reviewer; ICLR 2021 Reviewer; AAAI 2020,
                    2021 PC Member; ACCV 2020 PC Member; WACV 2021 PC Member.</li>
                  <li>IEEE Transactions on Pattern Analysis and Machine
                    Intelligence; IEEE Transactions on Image Processing; IEEE
                    Signal Processing Magazine; IEEE Transactions on Geoscience
                    and Remote Sensing; IEEE Signal Processing Letters; IEEE
                    Geoscience and Remote Sensing Letters; Remote Sensing;
                    Infrared Physics and Technology; International Journal of
                    Remote Sensing; Electronics; Journal of Computational
                    Methods in Sciences and Engineering; Journal of Marine
                    Science and Technology; Computational Intelligence and
                    Neuroscience; Journal of Spectroscopy; The Visual Computer;
                    International Journal of Machine Learning and Cybernetics.</li>
                  <li>Best Reviewer of Infrared Physics &amp; Technology (2017).</li>
                </ul>
              </div>
            </div>
          </div>
          <div class="container">
            <div class="panel panel-default">
              <div class="panel-heading"><b>Invited Talks</b></div>
              <div class="panel-body">
                <ul>
                  <li><b><b>Physics informed remote sensing image synthesis and analysis</b></b>.
                    Invited talk at VALSE 2023, Wuxi, China.
                    Jun 2023.</li>
                  <li><b><b>Mixed reality for visual perception of unmanned
                        systems</b></b>. Invited talk at Kwai, Beijing, China.
                    Feb 2023.</li>
                  <li><b><b>Deep Learning: History, Methodology, and
                        Applications</b></b>. Invited talk at North China
                    University of Technology, Beijing, China. Oct 2022</li>
                  <li><b>Mixed reality for visual perception of unmanned systems</b>.
                    Invited talk at HIT-Webinar, Beijing, China. Oct 2022.</li>
                  <li><b>Mixed reality and neural rendering for visual
                      perception</b>. Invited talk at BtyeDance, Mountain View,
                    USA and Beijing, China. Jan 2022.</li>
                  <li><b>Mixed reality and neural rendering for visual
                      perception</b>. Invited talk at OPPO Research Institute,
                    Beijing, China. Jan 2022.</li>
                  <li><b>Mixed reality and neural rendering for visual
                      perception</b>. Invited talk at NIO, Beijing, China. Dec
                    2021.</li>
                  <li><b>Mixed reality and neural rendering for visual
                      perception</b>. Invited talk at Didi Chuxing, Beijing,
                    China. Dec 2021.</li>
                  <li><b>Stylized Neural Painting</b>. TechBeat AI Talk. June
                    2021.</li>
                  <li><b>Stylized Neural Painting</b>. CVPR Oral. June 2021.</li>
                  <li><b>Art-centric Neural Rendering and Augmented Reality</b>.
                    University of Texas, Austin. Dec 2020.</li>
                  <li><b>Neural Rendering for Visual Editing and Visual Arts</b>.
                    Ocean University of China. Dec 2020.</li>
                  <li><b>Object Detection in 20 Years</b>. Didi Chuxing,
                    Beijing, China. Jul 2019.</li>
                  <li><b>Adversarial Training for Solving Inverse Problems</b>.
                    Didi Chuxing, Beijing, China. Jul 2019.</li>
                  <li><b>Introduction to Deep Learning and Computer Vision -
                      Past, Present and Future</b>. M-Culture Salon, University
                    of Michigan, Ann Arbor. Jan 2020.</li>
                </ul>
              </div>
            </div>
          </div>
          <div class="container">
            <div class="panel panel-default">
              <div class="panel-heading"><b>Summer Exchange</b> </div>
              <div class="panel-body">
                <ul>
                  <li>I was a summer exchange student at the <a href="https://www.cam.ac.uk/"

                      target="_blank">University of Cambridge</a> and the <a href="http://www.ox.ac.uk/"

                      target="_blank">University of Oxford</a>, U.K., in Jul
                    2017.</li>
                </ul>
              </div>
            </div>
          </div>
          <br>
          <div class="container">
            <p> </p>
            <br>
            <div style="text-align: center;"><i>Copyright (C) 2023 By Zhengxia
                Zou.</i></div>
            <br>
            <p> </p>
          </div>
        </div>
        <b> </b> </div>
    </div>
  </body>
</html>
