<html lang="en">
  <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-168911195-1"></script>
    <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-168911195-1');
</script> <title>Zhengxia Zou, Ph.D.</title>
    <title>Bootstrap Example</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.3.1.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <style type="text/css">
		.bgimg {
    background-image: url("zzx_gallery/logo.png");
    background-repeat: no-repeat;
    background-position: center; 
    position: relative;
		}
		</style>
  </head>
  <body>
    <div class="container">
      <div class="container">
        <nav class="nav nav-tabs">
          <li><a href="#me">About</a></li>
          <li><a href="#highlights">Research</a></li>
          <li><a href="#Publications">Publication</a></li>
          <li><a href="#Activities">Misc</a></li>
        </nav>
      </div>
      <div class="container">
        <div class="page-header">
          <h2 id="me">Zhengxia Zou, Ph.D.</h2>
        </div>
      </div>
      <div class="container">
        <div class="row">
          <div class="col-sm-4"> <img class="img-responsive img-rounded" style="width:100%"
              src="zzx_gallery/zzx3.jpg"> </div>
          <div class="col-sm-8">
            <p></p>
            I am currently a Professor at the School of Astronautics, <a href="https://www.buaa.edu.cn/"
              target="_blank">Beihang University</a>. I received my Ph.D. and
            B.S. from Beihang University in 2018 and 2013, supervised by Prof.
             <a href="http://levir.buaa.edu.cn/" target="_blank">Zhenwei Shi</a>.
            During 2018 - 2021, I was a postdoc research fellow at the <a href="https://umich.edu/"
              target="_blank">University of Michigan, Ann Arbor</a>, working
            with <a href="http://www.yelabs.net/" target="_blank">Prof. Jieping
              Ye</a> and <a href="https://traffic.engin.umich.edu/" target="_blank">Prof.
              Henry Liu</a>. I study computer vision, deep learning, and related problems in
            remote sensing and autonomous driving.
            <p></p>
            Email: zhengxiazou [at] gmail [dot] com; zhengxiazou [at] buaa [dot]
            edu [dot] cn
            <p></p>
            <a href="https://shi.buaa.edu.cn/zouzhengxia" target="_blank">[中文主页]</a>
            | <a href="https://scholar.google.com/citations?user=DzwoyZsAAAAJ&amp;hl=en"
              target="_blank">[Google Scholar Profile]</a> | <a href="https://github.com/jiupinjia"
              target="_blank">[Github Profile]</a><br>
            <p></p>
            <p><span style="color: #cc0000;">[Intern position]: I am hiring self-motivated graduate/undergraduate students. Intern positions are always
                available. Please email me with your CV if you are interested.</span>
            </p>
            <p>NEW (06/2024): Our research on generative foundational models for remote sensing was reported by the National Natural Science Foundation of China (NSFC).</p>
            <p>NEW (12/2023): I am organizing a special issue for the new Nature journal, Communications Engineering, which is the first Nature
              journal dedicated to the engineering field. The theme is “Technologies for Augmented and Virtual Reality.” Submissions are welcome.</p>
            <p>NEW (04/2023): Our paper on driving environment simulation got
              accepted to Nature Communications.</p>
            <p>NEW (03/2023): Our paper on autonomous vehicle testing got
              accepted to Nature (cover). Congratulations!</p>
            <p>NEW (02/2023): One paper accepted to CVPR 2023 (featured in New
              Scientist (新科学人)).</p>
            <p>NEW (01/2023): Our survey paper on object detection got accepted
              by Proceedings of the IEEE<em>.</em></p>
            <p> NEW (10/2022): I was listed in the top 2% scientists worldwide
              identified by Stanford University<em>.</em></p>
            <p>NEW (07/2022): One paper accepted to IEEE Transactions on Image
              Processing (TIP)<em>.</em></p>
            <p> </p>
          </div>
        </div>
      </div>
      <div class="container">
        <div class="page-header">
          <h2 id="highlights">Research Highlights</h2>
        </div>
      </div>
      <div class="container">
        <div class="panel panel-default">
          <div class="panel-heading"><b>Research impact, media coverage, and
              featured applications</b><br>
          </div>
          <div class="panel-body">
            <div class="row">
              <div class="col-sm-6">
                <ul>
                  <li><i>50+ peer-reviewed publications, including 30+ top-tier
                      journals and conferences ( Nature, Nat. Commun., Proc
                      IEEE, TPAMI, TIP, CVPR, ICCV, AAAI, ... )&nbsp; </i></li>
                  <li><i><i>3000+ Google Scholar citations, </i>4000+ GitHub
                      Stars/Forks </i></li>
                  <li><i> Two papers selected in PaperWithCode "Top-10 Trending
                      Research" and "GitHub Trending Repositories"<b><br>
                      </b></i></li>
                </ul>
              </div>
              <div class="col-sm-6">
                <ul>
                  <li><i>Featured in 10+ platforms with over 10M registered
                      users worldwide, including </i><i><i><i><a href="https://mcity.umich.edu/"

                            target="_blank">MCITY</a>,</i> </i></i><i> <a href="https://apps.apple.com/us/app/remini-ai-photo-enhancer/id1470373330"

                        target="_blank"> REMINI</a>, <a href="https://apps.apple.com/cn/app/%E4%BD%A0%E6%88%91%E5%BD%93%E5%B9%B4/id1461690800?l=en"

                        target="_blank">你我当年</a>, </i><i><a href="https://n.163.com/"

                        target="_blank">Justice</a>, <a href="https://apps.apple.com/cn/app/%E4%BD%A0%E6%88%91%E5%BD%93%E5%B9%B4-%E7%85%A7%E7%89%87%E8%A7%86%E9%A2%91%E5%8F%98%E9%AB%98%E6%B8%85-%E8%80%81%E7%85%A7%E7%89%87%E4%BF%AE%E5%A4%8D%E8%A7%86%E9%A2%91%E7%94%BB%E8%B4%A8%E4%BC%98%E5%8C%96%E5%A2%9E%E5%BC%BA/id1461690800"

                        target="_blank">Heaven Mobile</a>, <a href="https://wandb.ai/site"

                        target="_blank">Weights&amp;Biases</a>, <a href="https://replicate.ai/"

                        target="_blank">REPLICATE AI</a>, <a href="https://runwayml.com/"

                        target="_blank"> RUNWAYML</a></i><i>...<br>
                    </i></li>
                  <li><i>Covered by 30+ high-impact tech-media, including</i><i><i>
                      </i></i><i><i><i><i><a href="http://www.news.cn/politics/2022-03/02/c_1128428941.htm"

                              target="_blank">新华社</a>,</i></i> <a href="http://tv.cctv.com/2022/01/19/VIDEJ78zT7md9otWzW5qgT6N220119.shtml"

                          target="_blank">中央电视台</a>,</i><a href="https://thenextweb.com/neural/2020/11/16/this-open-source-ai-tool-can-make-your-video-spectacular-with-sky-replacement-effects/"

                        target="_blank"> TheNextWeb</a>, <a href="https://www.newscientist.com/article/2362730-character-creator-ai-puts-barack-obama-or-anyone-in-a-video-game/"

                        target="_blank">New Scientist</a>, <a href="https://www.jiqizhixin.com/articles/2020-10-25"

                        target="_blank">机器之心</a>, <a href="https://mp.weixin.qq.com/s/xowoCSI6yIrzPTavz4OiLg"

                        target="_blank">量子位</a>...</i> </li>
                </ul>
              </div>
            </div>
          </div>
        </div>
        <div class="container">
          <div class="page-header">
            <h2 id="Publications">Selected Publications</h2>
          </div>
        </div>
        <div class="container">
          <div class="panel panel-default">
            <div class="panel-heading"><b>Selected publications and preprints
                (*For my full publication list, please go to my <a href="https://scholar.google.com/citations?user=DzwoyZsAAAAJ&amp;amp;hl=en"

                  target="_blank">google scholar profile</a>)</b> </div>
            <div class="panel-body">
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-DetectionSurvey.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p> <b>Zhengxia Zou*</b> (*Corresponding author), Zhenwei
                    Shi, Yuhong Guo, and Jieping Ye (*Corresponding author).
                    Object Detection in 20 Years: A Survey. <i>Proceedings of
                      the IEEE</i>, Volumn 111, Issue 13, 2023. [1500+ citations], <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5"
                      target="_blank">Most Popular Article of the PIEEE 2023</a>. <a href="https://ieeexplore.ieee.org/document/10028728"
                      target="_blank">[PDF]</a></p>
                   Extensively reviews the fast-moving research field of object detection in the light of technical evolution,
                  spanning over a quarter-century's time (from the 1990s to 2022). A number of
                  topics are covered in this paper, including milestone
                  detectors, detection datasets, metrics, fundamental building
                  blocks of detection systems, speed up techniques, and the
                  recent state of the art detection methods.
                  <p></p>
                  <b>- High-impact citations:&nbsp;</b> <a href="http://cs231n.stanford.edu/"

                    target="_blank"><u>Stanford CS231n: Convolutional Neural
                      Networks for Visual Recognition (2019-2023).</u></a>
                  <p></p>
                  <p></p>
                  <b>- Media coverage:</b> <a href="https://proceedingsoftheieee.ieee.org/category/media-room/blog/"

                    target="_blank"><u>[PIEEE] Proceedings of the IEEE Paper Explores Object Detection's Evolution and Future Directions</u></a>&nbsp;|

                  <a href="https://www.zhuanzhi.ai/document/50b8a2fec4a9ad5561b8694d16a1dffb"

                    target="_blank"><u>[专知] 密歇根大学40页最新论文带你全面了解目标检测</u></a>&nbsp;
                  <p></p>
                  <b>- In other languages:</b>&nbsp; <a href="https://ai.yanxishe.com/page/postDetail/14275"

                    target="_blank"><u>English-to-Chinese (1)</u></a> |&nbsp; <a

                    href="https://blog.csdn.net/clover_my/article/details/92794719"

                    target="_blank"><u>English-to-Chinese (2)</u></a>&nbsp;
                  <p></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-NeuralNDE.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p> Xintao Yan+, <b><strong></strong>Zhengxia Zou</b>+
                    (+equal contribution), Shuo Feng, Haojie Zhu, Haowei Sun,
                    Henry X. Liu* (*Corresponding author)<strong></strong>.
                    Learning Naturalistic Driving Environment with Statistical
                    Realism. <i><i>Nature Communications (featured image), 2023</i>. </i>Featured
                    in <a target="_blank" href="https://www.nature.com/collections/hjhbgijcei">Editors'
                      Highlights</a>.<i> </i><a href="https://www.nature.com/articles/s41467-023-37677-5"

                      target="_blank">[PDF]</a><em> </em><a href="https://github.com/michigan-traffic-lab/Learning-Naturalistic-Driving-Environment"

                      target="_blank">[Github]</a>&nbsp;<i> </i></p>
                  <p>We develop NeuralNDE, a Transformer-based framework to
                    learn multi-agent interaction behavior from real-world
                    vehicle trajectory data. NeuralNDE can achieve both accurate
                    safety-critical and normal driving statistics.</p>
                  <p> </p>
                  <p></p>
                  <b>- Media coverage:&nbsp; </b><a href="https://www.eurekalert.org/news-releases/987857"

                    target="_blank"><u>[EurekAlert]</u></a> <a href="https://techxplore.com/news/2023-05-world-realistic-simulated-environment-based.html"

                    target="_blank"><u>[TechXplore]</u></a> <a href="https://news.umich.edu/worlds-first-realistic-simulated-driving-environment-based-on-crash-prone-michigan-intersection/"

                    target="_blank"><u>[Michigan News] World’s first realistic
                      simulated driving environment based on ‘crash-prone’
                      Michigan intersection.</u></a> | <a href="https://www.sohu.com/a/674403685_610300"

                    target="_blank"><u>[量子位]
                      自动驾驶仿真系统登Nature子刊，准确建模事故率事故类型，全华人团队打造</u></a> | <a href="https://www.mittrchina.com/news/detail/11938"

                    target="_blank"><u>[MIT科技评论]
                      密西根大学团队开发高精度自然驾驶仿真算法，为自动驾驶开发提供仿真基础</u></a>
                  <p></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/nature.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p> Shuo Feng, Haowei Sun, Xintao Yan, Haojie Zhu, <b>Zhengxia
                      Zou</b>, Shengyin Shen, Henry X. Liu* (*Corresponding
                    author). Dense Reinforcement Learning for Safety Validation
                    of Autonomous Vehicles. <i>Nature (cover)</i>, 2023<i>.</i>
                    <em> </em><a href="https://www.nature.com/articles/s41586-023-05732-2"

                      target="_blank">[PDF]</a><em> </em><a href="https://github.com/michigan-traffic-lab/Dense-Deep-Reinforcement-Learning"

                      target="_blank">[Github]</a>&nbsp;<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9197693"

                      target="_blank"></a><i> </i></p>
                  <p>One critical bottleneck that impedes the development and
                    deployment of autonomous vehicles is the prohibitively high
                    economic and time costs required to validate their safety in
                    a naturalistic driving environment, owing to the rarity of
                    safety-critical events. Here we report the development of an
                    intelligent testing environment, where
                    artificial-intelligence-based background agents are trained
                    to validate the safety performances of autonomous vehicles
                    in an accelerated mode, without loss of unbiasedness.</p>
                  <p> </p>
                  <p> </p>
                  <b>- Media coverage:</b> <a href="https://www.nature.com/articles/d41586-023-00798-4"

                    target="_blank"><u>[Nature News] Hazards help autonomous
                      cars to drive safely.</u></a> | <a href="https://www.nature.com/articles/d41586-023-00867-8"

                    target="_blank"><u>[Nature Podcast] How to make driverless
                      cars safer — expose them to lots of dangerous drivers</u></a>
                  | <a href="https://news.engin.umich.edu/2023/03/simulated-terrible-drivers-cut-the-time-and-cost-of-av-testing-by-a-factor-of-one-thousand/"

                    target="_blank"><u>[Michigan Engineering] Simulated terrible
                      drivers cut the time and cost of AV testing by a factor of
                      one thousand</u></a>
                  <p></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-T2P.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p> Rui Zhao, Wei Li, Zhipeng Hu, Lincheng Li* (*Corresponding
                    author), <b>Zhengxia Zou*</b> (*Corresponding author),
                    Zhenwei Shi, Changjie Fan<strong></strong>. Zero-Shot
                    Text-to-Parameter Translation for Game Character
                    Auto-Creation. Accepted to <em><em>IEEE Conference on
                        Computer Vision and Pattern Recognition (CVPR) 2023</em></em><i>.</i><i>
                    </i><a href="https://arxiv.org/abs/2303.01311" target="_blank">[PDF]</a>
                  </p>
                  <p> </p>
                  <b>- Featured apps:</b> Justice Mobile (The first plausible
                  solution for text-driven game characters auto-creation).
                  <p></p>
                  <p> </p>
                  <b>- Media coverage:</b> <a href="https://www.newscientist.com/article/2362730-character-creator-ai-puts-barack-obama-or-anyone-in-a-video-game/"

                    target="_blank"><u>[New Scientist (新科学人)] Character creator
                      AI puts Barack Obama – or anyone – in a video game</u></a>
                  <br>
                  <p></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-FaceParams-pami.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p> Tianyang Shi+, <b><strong></strong>Zhengxia Zou</b>+
                    (+equal contribution), Zhenwei Shi, and Yi Yuan*
                    (*Corresponding author)<strong></strong>. Neural Rendering
                    for Game Character Auto-creation. <i><i>IEEE Transactions
                        on Pattern Analysis and Machine Intelligence, 2022</i>.
                    </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9197693"

                      target="_blank">[PDF]</a> <br>
                  </p>
                  <p> </p>
                  <b>- Featured apps:</b> <a href="https://n.163.com/" target="_blank">Justice</a>
                  and <a href="https://apps.apple.com/cn/app/%E4%BD%A0%E6%88%91%E5%BD%93%E5%B9%B4-%E7%85%A7%E7%89%87%E8%A7%86%E9%A2%91%E5%8F%98%E9%AB%98%E6%B8%85-%E8%80%81%E7%85%A7%E7%89%87%E4%BF%AE%E5%A4%8D%E8%A7%86%E9%A2%91%E7%94%BB%E8%B4%A8%E4%BC%98%E5%8C%96%E5%A2%9E%E5%BC%BA/id1461690800"

                    target="_blank">Heaven Mobile</a>, two MMO-RPGs with 10M+
                  players worldwide
                  <p></p>
                  <p> </p>
                  <b>- Media coverage:</b> <a href="http://tv.cctv.com/2022/01/19/VIDEJ78zT7md9otWzW5qgT6N220119.shtml"

                    target="_blank"><u>[CCTV经济信息联播]元宇宙应用渐热 记者走入“元宇宙”
                      体验个性化“捏脸”和动作捕捉</u></a> | <a href="https://www.jiqizhixin.com/articles/2019-09-09-18"

                    target="_blank"><u>[机器之心] 只需一张自拍，网易伏羲用这种方法直接生成「个人专属」游戏角色</u></a><br>
                  <p></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-SkyAR.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p> <b>Zhengxia Zou </b>(*Corresponding author), Rui Zhao,
                    Tianyang Shi, Shuang Qiu, and Zhenwei Shi. Castle in the
                    Sky: Dynamic Sky Replacement and Harmonization in Videos. <em>IEEE
                      Transactions on Image Processing,</em> 2022. In press. <a

                      href="https://arxiv.org/abs/2010.11800" target="_blank">[PDF]</a><em>
                    </em><a href="https://jiupinjia.github.io/skyar/" target="_blank">[Project]</a>
                    [<a target="_blank" href="https://github.com/jiupinjia/SkyAR">GitHub
                      (2.0k☆)</a>]</p>
                  <p><b><b><b>- Featured </b>apps:</b></b><span style="color: #337ab7;"></span>
                    <a href="https://wandb.ai/wandb/skyAR/reports/The-Sky-Is-In-Our-Grasp---VmlldzozMjY0NDI"

                      target="_blank"><u>Weights &amp; Biases</u></a>, a ML
                    developer tool with 100,000+ practitioners </p>
                  <p> </p>
                  <b>- Media coverage:</b> <a href="https://www.jiqizhixin.com/articles/2020-10-25"

                    target="_blank"><u>[机器之心]
                      建造自己的“天空之城”，密歇根大学博士后的这项研究可以虚空造物、偷天换日</u></a> | <a href="https://thenextweb.com/neural/2020/11/16/this-open-source-ai-tool-can-make-your-video-spectacular-with-sky-replacement-effects/"

                    target="_blank"><u>[TNW] This open-source AI tool can make
                      your video spectacular with...</u></a>
                  <p></p>
                  <span style="color: #337ab7;"></span> <span style="color: #337ab7;">
                  </span>
                  <p></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-roadside.jpg"><br>
                  <br>
                </div>
                <div class="col-sm-9">
                  <p></p>
                  <p> <b>Zhengxia Zou</b>, Rusheng Zhang, Shengyin Shen, Gaurav
                    Pandey, Punarjay Chakravarty, Armin Parchami, and Henry X.
                    Liu (*Corresponding author). Real-time Full-stack Traffic
                    Scene Perception for Autonomous Driving with Roadside
                    Cameras. <em><i>The International Conference on Robotics
                        and Automation (ICRA), 2022</i></em><em><i><em></em></i><em></em><em></em>.</em><a

                      href="https://www.youtube.com/watch?v=RkiKe5UNzXA" target="_blank">
                      <em> </em></a><a href="https://arxiv.org/abs/2206.09770"

                      target="_blank">[PDF]</a> <a href="https://www.youtube.com/watch?v=RkiKe5UNzXA"

                      target="_blank">[1min-DemoVideo] </a> </p>
                  <p> <b>- Featured apps:</b> Deployed at a two-lane roundabout
                    located at Ellsworth Rd. and State St., Ann Arbor, MI, USA,
                    providing 7x24 real-time traffic flow monitoring for
                    hazardous driving scenarios identification.</p>
                </div>
              </div>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-ImMPI.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p> Yongchang Wu, <b>Zhengxia Zou</b>* (*Corresponding
                    author), and Zhenwei Shi. Remote Sensing Novel View
                    Synthesis with Implicit Multiplane Representations. <i><em>IEEE
                        Transactions on Geoscience and Remote Sensing, 2022</em></i><em></em><em><i><em></em></i><em></em><em></em>.</em>
                    <em> </em><a href="https://arxiv.org/abs/2205.08908" target="_blank">[PDF]</a><em>
                    </em><a href="https://github.com/wyc-Chang/ImMPI" target="_blank">[Github]</a>
                  </p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-Finegrained.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p>Jianqi Chen, Keyan Chen, Hao Chen, Wenyuan Li, <b>Zhengxia
                      Zou</b>* (*Corresponding author), and Zhenwei Shi.
                    Contrastive Learning for Fine-grained Ship Classification in
                    Remote Sensing Images.&nbsp; <i><em>IEEE Transactions on
                        Geoscience and Remote Sensing, 2022</em></i>. <em> </em><a

                      href="https://ieeexplore.ieee.org/document/9832938/" target="_blank">[PDF]</a><em></em>
                  </p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-PDASS.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p> Liqin Liu, Wenyuan Li, Zhenwei Shi, and <b>Zhengxia Zou</b>*
                    (*Corresponding author). Physics-informed Hyperspectral
                    Remote Sensing Image Synthesis with Deep Conditional
                    Generative Adversarial Networks.&nbsp; <i><em>IEEE
                        Transactions on Geoscience and Remote Sensing, 2022</em></i>.
                    <em> </em><a href="https://ieeexplore.ieee.org/document/9770778/"

                      target="_blank">[PDF]</a><em> </em><a href="https://github.com/liuliqin/PDASS-Physics-informed-HSI-Synthesis-with-Deep-CGAN"

                      target="_blank">[Github]</a> </p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-SSMCT.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p> Yinglin Duan, Yue Lin, <b>Zhengxia Zou</b>*
                    (*Corresponding author), Yi Yuan, Zhehui Qian, Bohan Zhang.
                    A Unified Framework for Real Time Motion Completion.&nbsp;<em><i>AAAI
                        Conference on Artificial Intelligence (AAAI) 2022</i></em><em><em>,
                        <span style="color: #cc0000;">Oral Presentation</span></em></em><em><i><em></em></i><em></em><em></em>.
                    </em><a target="_blank" href="https://ojs.aaai.org/index.php/AAAI/article/view/20368">[PDF]</a><em><br>
                    </em></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-painting.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p> <b>Zhengxia Zou </b>(*Corresponding author), Tianyang
                    Shi, Shuang Qiu, Yi Yuan, and Zhenwei Shi. Stylized Neural
                    Painting.&nbsp;<em><em>IEEE Conference on Computer Vision
                        and Pattern Recognition (CVPR) 2021, <span style="color: #cc0000;">Oral
                          Presentation</span>.</em></em><em> </em><a href="https://arxiv.org/abs/2011.08114"

                      target="_blank">[PDF]</a><em> </em><a href="https://jiupinjia.github.io/neuralpainter/"

                      target="_blank">[Project] </a><a href="https://github.com/jiupinjia/stylized-neural-painting"

                      target="_blank">[GitHub (1.5k☆)]</a></p>
                  <p> <b><b>- Featured </b>apps:</b> <a href="https://play.google.com/store/apps/details?id=com.bigwinepot.nwdn.international&amp;hl=en_US&amp;gl=US"

                      target="_blank">REMINI</a> and <a href="https://apps.apple.com/cn/app/%E4%BD%A0%E6%88%91%E5%BD%93%E5%B9%B4-%E7%85%A7%E7%89%87%E8%A7%86%E9%A2%91%E5%8F%98%E9%AB%98%E6%B8%85-%E8%80%81%E7%85%A7%E7%89%87%E4%BF%AE%E5%A4%8D%E8%A7%86%E9%A2%91%E7%94%BB%E8%B4%A8%E4%BC%98%E5%8C%96%E5%A2%9E%E5%BC%BA/id1461690800"

                      target="_blank">你我当年</a>, two photo editors with 10M+
                    users worldwide | <b> </b><span style="color: #337ab7;"></span>
                    <a href="https://runwayml.com/" target="_blank">RunwayML</a>,
                    a web-based video editor</p>
                  <p> </p>
                  <b>- Media coverage:</b>&nbsp; <a href="http://www.news.cn/politics/2022-03/02/c_1128428941.htm"

                    target="_blank"><u>[新华社] 动动手，一起为春天中国“添彩” - 送您一支AI画笔,
                      为祖国春天涂抹万千风情</u></a> |&nbsp; <a href="https://www.jiqizhixin.com/articles/2021-04-21-5"

                    target="_blank"><u>[机器之心] 有了这支矢量神经风格画笔，无需GAN也可生成精美绘画</u></a>
                  | <a href="https://www.marktechpost.com/2020/11/22/stylized-neural-painter-an-image-to-painting-translation-method-that-generates-vivid-and-realistic-painting-artworks-with-controllable-styles/"

                    target="_blank"><u>[MarkTechPost] An Image-To-Painting
                      Translation Method That Generates Painting Artworks With
                      Controllable Styles</u></a>
                  <p></p>
                  <span style="color: #337ab7;"> </span>
                  <p></p>
                  <p></p>
                  <b></b>
                  <p></p>
                  <p></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-DAD.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p> <b>Zhengxia Zou</b> (*Corresponding author), Sen Lei,
                    Tianyang Shi, Zhenwei Shi, and Jieping Ye. Deep Adversarial
                    Decomposition: A Unified Framework for Separating
                    Superimposed Images. <em>IEEE Conference on Computer Vision
                      and Pattern Recognition (CVPR) 2020. </em><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Zou_Deep_Adversarial_Decomposition_A_Unified_Framework_for_Separating_Superimposed_Images_CVPR_2020_paper.pdf"

                      target="_blank">[PDF]</a><em></em> <a href="https://github.com/jiupinjia/Deep-adversarial-decomposition"

                      target="_blank">[Github]</a></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"><img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-inverseGANs.jpg"></div>
                <div class="col-sm-9">
                  <p></p>
                  <p> <b>Zhengxia Zou</b> (*Corresponding author), Tianyang
                    Shi, Zhenwei Shi, and Jieping Ye. Adversarial Training for
                    Solving Inverse Problems in Image Processing. <i><em>IEEE
                        Transactions on Image Processing, </em></i><em>2021. </em><a

                      href="https://ieeexplore.ieee.org/document/9337199" target="_blank">[PDF]</a><em>
                    </em><a href="https://www.youtube.com/watch?v=3ZNinJUlXNc" target="_blank">[1min-DemoVideo]</a>
                    <a href="https://github.com/jiupinjia/GANs-for-Inverse-Problems"

                      target="_blank">[Github]</a></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-cloudgan.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p> <b>Zhengxia Zou</b> (*Corresponding author), Wenyuan Li,
                    Tianyang Shi, Zhenwei Shi, and Jieping Ye. Generative
                    Adversarial Training for Weakly Supervised Cloud Matting. <i>IEEE
                      International Conference on Computer Vision (ICCV) 2019.</i>
                    <a href="http://openaccess.thecvf.com/content_ICCV_2019/html/Zou_Generative_Adversarial_Training_for_Weakly_Supervised_Cloud_Matting_ICCV_2019_paper.html"

                      target="_blank">[PDF]</a> <a href="https://github.com/jiupinjia/CloudMattingGAN"

                      target="_blank">[Github]</a></p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-RAM.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p><strong>Zhengxia Zou</strong>, and Zhenwei Shi
                    (*Corresponding author). Random access memories: A new
                    paradigm for target detection in high resolution aerial
                    remote sensing images.&nbsp;<i><i><i><em>IEEE Transactions
                            on Image Processing,</em></i> 2018</i>.</i></p>
                  <p> </p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-SVDNet.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p><b>Zhengxia Zou</b>, and Zhenwei Shi (*Corresponding
                    author). Ship Detection in Spaceborne Optical Image With SVD
                    Networks.&nbsp;<i><i><i><em>IEEE Transactions on Geoscience
                            and Remote Sensing,</em></i> 2016</i>.</i></p>
                  <p> </p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-RSCaption.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p>Zhenwei Shi, and <b>Zhengxia Zou</b>* (Corresponding
                    author). Can a machine generate humanlike language
                    descriptions for a remote sensing image? <i><i><i><em>IEEE
                            Transactions on Geoscience and Remote Sensing,</em></i>
                        2017</i>.</i></p>
                  <p> </p>
                </div>
              </div>
              <br>
              <div class="row">
                <div class="col-sm-3"> <img class="img-thumbnail" style="width:100%"

                    src="zzx_gallery/thumb-HCEM.jpg"> </div>
                <div class="col-sm-9">
                  <p></p>
                  <p><b>Zhengxia Zou</b>, and Zhenwei Shi (*Corresponding
                    author). Hierarchical suppression method for hyperspectral
                    target detection. <i>IEEE Transactions on Geoscience and
                      Remote Sensing, 2015.</i></p>
                  <p> </p>
                </div>
              </div>
              <br>
            </div>
          </div>
          <div class="container">
            <div class="page-header">
              <h2 id="Activities">Teaching and Academic Activities</h2>
            </div>
          </div>
          <div class="container">
            <div class="panel panel-default">
              <div class="panel-heading"><b>Teaching</b> </div>
              <div class="panel-body">
                <ul>
                  <li><b>Fundamentals of Mathematics for Machine Learning</b>, undergraduate course, 2023/2024 Spring, 48/48 Hours.</li>
                  <li><b>Pattern Recognition, undergraduate course</b>, 2023/2024 Spring, 16/ 48 Hours.</li>
                  <li><b>Principles of Intelligent Detection and Control in Aerospace</b>, undergraduate course, 2022/2023 Fall, 16/48 Hours.</li>
                  <li><b>Intelligent Perception Micro-Class</b>, 2024 Spring, 16/16 Hours.</li>
                  <li><b>Theoretical and Frontier Research in Intelligent Information Processing</b>, Ph.D. Course, 2024 Fall, 10/32 Hours.</li>
                  <li><b>Deep Learning for Remote Sensing Image Processing</b>, International Students (English), 2023 Fall, 16/16 Hours.</li>
                </ul>
              </div>
            </div>
          </div>
          <div class="container">
            <div class="panel panel-default">
              <div class="panel-heading"><b>Academic Service</b> </div>
              <div class="panel-body">
                <ul>
                  <li>Secretary-General, Publicity Working Committee, China Society of Image and Graphics (2022-Present).</li>
                  <li>Committee Member, Remote Sensing Image Professional Committee, China Society of Image and Graphics (2023-Present).</li>
                  <li>Academic Advisor, NetEase Fuxi AI Lab (2019-2021).</li>
                </ul>
              </div>
            </div>
          </div>
          <div class="container">
            <div class="panel panel-default">
              <div class="panel-heading"><b>Editor Service</b> </div>
              <div class="panel-body">
                <ul>
                  <li>Communications Engineering (Nature) Special Issue: "Technologies for Augmented and Virtual Reality". Deadline for manuscript submissions: 21 Jun 2024.</li>
                  <li>Executive Editor, Special Issue on Intelligent Remote Sensing Applications, Journal of Space Science and Technology.</li>
                  <li>Editorial Board Member, Journal of Computer Graphics.</li>
                  <li>Remote Sensing, Special Issue: "Pattern Recognition and Image Processing for Remote Sensing II". Guest Editor. Closed.</li>
                  <li>Remote Sensing, Special Issue: "Advanced Learning Techniques for Remote Sensing Image Quality Improvement".  Guest Editor. Closed.</li>
                  <li>Remote Sensing, Special Issue: "Computational Intelligence and Advanced Learning Techniques in Remote Sensing".  Guest Editor. Closed.</li>
                </ul>
              </div>
            </div>
          </div>
          <div class="container">
            <div class="panel panel-default">
              <div class="panel-heading"><b>Journal Review Service</b> </div>
              <div class="panel-body">
                <ul>
                  <li>IEEE Transactions on Pattern Analysis and Machine Intelligence.</li>
                  <li>IEEE Transactions on Image Processing.</li>
                  <li>IEEE Signal Processing Magazine.</li>
                  <li>IEEE Transactions on Geoscience and Remote Sensing.</li>
                  <li>IEEE Transactions on Circuits and Systems for Video Technology.</li>
                  <li>IEEE Transactions on Intelligent Vehicles.</li>
                  <li>Transportation Research Part C.</li>
                  <li>ISPRS Journal of Photogrammetry and Remote Sensing.</li>
                  <li>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing.</li>
                  <li>IEEE Geoscience and Remote Sensing Letters.</li>
                  <li>Remote Sensing.</li>
                  <li>International Journal of Remote Sensing.</li>
                  <li>GIScience & Remote Sensing.</li>
                  <li>Information Fusion.</li>
                  <li>IEEE Signal Processing Letters.</li>
                  <li>Infrared Physics & Technology.</li>
                  <li>Electronics.</li>
                  <li>Journal of Computational Methods in Sciences and Engineering.</li>
                  <li>Journal of Marine Science and Technology.</li>
                  <li>Computational Intelligence and Neuroscience.</li>
                  <li>Journal of Spectroscopy.</li>
                  <li>International Journal of Machine Learning and Cybernetics.</li>
                  <li>Journal of Space Science and Technology.</li>
                  <li>Journal of Computer Graphics.</li>
                </ul>
              </div>
            </div>
          </div>
          <div class="container">
            <div class="panel panel-default">
              <div class="panel-heading"><b>Conference Review Service</b> </div>
              <div class="panel-body">
                <ul>
                  <li>Conference on Neural Information Processing Systems (NeurIPS) 2019/2020, PC Member.</li>
                  <li>International Joint Conference on Artificial Intelligence (IJCAI) 2021, Senior Program Committee (SPC).</li>
                  <li>The International Conference on Learning Representations (ICLR) 2021, Reviewer.</li>
                  <li>AAAI Conference on Artificial Intelligence (AAAI) 2020/2021, PC Member.</li>
                  <li>IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) 2020/2021/2022/2023, Reviewer.</li>
                  <li>IEEE International Conference on Computer Vision (ICCV), 2021/2023, Reviewer.</li>
                  <li>Asian Conference on Computer Vision, 2020, Reviewer.</li>
                  <li>Winter Conference on Applications of Computer Vision (WACV) 2021, Reviewer.</li>
                </ul>
              </div>
            </div>
          </div>
          <div class="container">
            <div class="panel panel-default">
              <div class="panel-heading"><b>Invited Talk</b></div>
              <div class="panel-body">
                <ul>
                  <li>2024-05. Generative Remote Sensing Foundation Models. CCIG 2024.</li>
                  <li>2024-04. Perception and Simulation Based on Mixed Reality. VALSE Webinar.</li>
                  <li>202402. Introduction to Perception and Countermeasures in Unmanned Systems. Beijing Institute of Environmental Features, CASIC.</li>
                  <li>2023.12. Physics-Driven Remote Sensing Image Synthesis and Interpretation. CSIG Youth Scientist Conference 2023.</li>
                  <li>2023-07. Advances in Intelligent Perception and Generation. Institute of Computing Technology, Chinese Academy of Sciences.</li>
                  <li>2023-06. Physics-Driven Remote Sensing Image Synthesis and Interpretation. VALSE 2023.</li>
                  <li>2023-04. Current Status and Development Trends of Intelligent Remote Sensing Technology. State Grid Corporation of China.</li>
                  <li>2023-02. Perception and Mixed Reality for Unmanned Systems. Kwai.</li>
                  <li>2022-10. Deep Learning: History, Methodology, and Applications. North China University of Technology.</li>
                  <li>2022-10. Perception and Mixed Reality for Unmanned Systems. HIT-Webinar.</li>
                  <li>2022-10. Mixed Reality and Neural Rendering for Visual Perception. ByteDance.</li>
                  <li>2022-01. Neural Rendering for Visual Perception. OPPO Research Institute.</li>
                  <li>2021-12. Neural Rendering for Visual Perception. NIO Autonomous Driving Division.</li>
                  <li>2021-12. Neural Rendering for Visual Perception. Didi Chuxing.</li>
                  <li>2021-06. Stylized Neural Painting. TechBeat AI Talk.</li>
                  <li>2020-12. Art-centric Neural Rendering and Augmented Reality. University of Texas, Austin.</li>
                  <li>2020-12. Neural Rendering for Visual Editing and Visual Arts. Ocean University of China.</li>
                  <li>2020-01. Introduction to Deep Learning and Computer Vision - Past, Present, and Future. University of Michigan, Ann Arbor, M-Culture Salon.</li>
                  <li>2019-07. Object Detection in 20 Years.  Didi AI Labs.</li>
                  <li>2019-07: Adversarial Training for Solving Inverse Problems. Didi AI Labs.</li>
                </ul>
              </div>
            </div>
          </div>
          <br>
          <div class="container">
            <p> </p>
            <br>
            <div style="text-align: center;"><i>Copyright (C) 2023 By Zhengxia
                Zou.</i></div>
            <br>
            <p> </p>
          </div>
        </div>
        <b> </b> </div>
    </div>
  </body>
</html>
